---
title: "Diagnosis vs. Relapse Signaling Analysis"
author: "tkeyes"
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: true
---

```{r signaling_setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# Libraries
library(magrittr)
library(tidyverse)
library(EMDomics)
library(Rtsne)
library(pheatmap)

# Parameters
input_path <- here::here("data", "AML_matrix_clustered.rds")

CLASSIFIER_POPULATIONS <- 
  c(
    'HSC',
    'MPP',
    'CMP',
    'GMP',
    'MEP',                          
    'Monocyte', 
    'DC', 
    'Macrophage', 
    'Thrombocyte'
  )

#===============================================================================

#source necessary files
source('~/GitHub/aml-cells/scripts/setup/marker_setup.R')
source('~/GitHub/aml-cells/scripts/setup/patient_setup.R')

```


In this analysis, we take a look at the difference in the Earth Mover's Distance (Wasserstein Distance) between signaling parameters in our mass cytometry AML dataset. 

## Background 

Broadly speaking, the Earth Mover's Distance (EMD) computes the "work" needed to transform one distribution into another. In molecular/systems biology, EMD is often used to compare marker distributions between various conditions (diagnosis and relapse, treatment and not treatment, stimulation vs. not stimulation, etc.).  

Unlike traditional methods of comparing measurements of central tendency (such as mean or median) between marker distributions in 1 or more conditions, EMD takes into account that distributions may shift in subtle ways: even if their means/medians do not change much, the distributions may change a great deal in terms of how they are shaped *outside* the areas of central tendency. For this reason, EMD is generally preferable to using the mean/median when the distributions you're working with are irregularly shaped (for instance, highly skewed or multimodal, since mean and median are generally less informative in these kinds of distributions). 

Here, we will perform some EMD calculations and then manually investigate signaling distributions between relapse and diagnostic samples in pediatric AML that has been stimulated in several conditions relative to baseline (`basal`): 

* IL-3
* IL-6
* GM-CSF
* HS5 (stromal cell line) conditioned media
* Pervandate (positive control)

## Basic setup

Algorithm (in words): 

* Read in previously pre-processed data
  * arcsinh transformation
  * compensation
  * filtered on `time` variable to remove weird CD34/CD38 "debarcode-gate"
* filter to only include paired samples (with both `Dx` and `Rx` present as well as healthy controls)

```{r}
#### set up global varibles
marker_setup()
patient_setup()

recode_vars <- 
  tibble(
    from = 1:length(CLASSIFIER_POPULATIONS), 
    to = CLASSIFIER_POPULATIONS
  ) %>% 
  deframe()

#read in paired data (and healthy data) 
aml_data <- 
  input_path %>% 
  read_rds() %>%
  mutate(
    patient = 
      patient %>% 
      as.character() %>% 
      str_to_lower() %>% 
      if_else(. == "pastrp", "pasrtp", .), 
    Mah.cluster = 
      recode(Mah.cluster, !!! recode_vars) %>% 
      factor(levels = CLASSIFIER_POPULATIONS)
  ) %>% 
  mutate_at(
    .vars = vars(phenograph.metacluster, FlowSOM.cluster, FlowSOM.metacluster),
    ~ (.) %>% 
      as.character() %>% 
      fct_reorder(., CD34, .fun = mean, .desc = TRUE)
  ) %>% 
  filter(patient %in% c(PAIRED_PATIENTS, HEALTHY_CONTROLS)) %>% 
  rename_at(
    vars(everything()), 
    ~ (.) %>% 
      str_to_lower() %>% 
      str_replace_all(pattern = "[:punct:]", replacement = "_")
  )
```


## Testing our implementation of EMD 

First, we simulate some data from two conditions (`A` and `B`) to make sure that we find a difference > 0. 

Note that the distibutions are drawn from populations with the same mean and sd, indicating that even with highly similar characteristics overall, EMD can find subtle differences. 

```{r}
sim_data <- 
  tibble(
    data = rnorm(100), 
    sample_name = paste("sample", 1:100), 
    group = c(rep("A", 50), rep("B", 50))
  )

ggplot(sim_data, aes(data, fill = group)) + geom_density(alpha = 0.5)
```

```{r}
calculate_emd_gene(
  vec = setNames(sim_data$data, sim_data$sample_name), 
  outcomes = setNames(sim_data$group, sim_data$sample_name), 
  sample_names = sim_data$sample_name, 
  binSize = 0.1
) %>% 
  knitr::kable()
```

We can also show that, if we translate population `B` gradually larger distances from population A, we will  return higher EMD values (as expected). 

```{r}
tibble(
  added_value = 0:10, 
) %>% 
  mutate(
    emd = 
      map_dbl(
        added_value, 
        ~ sim_data %>% 
          mutate(data = if_else(group == "A", data + 0, data + .x)) %>% 
          summarize(
            emd = 
              calculate_emd_gene(
                vec = setNames(data, sample_name),
                outcomes = setNames(group, sample_name), 
                sample_names = sample_name, 
                binSize = 0.1
              )
          ) %>% 
          pull(emd)
      )
  ) %>% 
  knitr::kable()
```

And we can see that the more we add to the distribution for `B`, the higher the EMD we get (as expected).

We can also illustrate that two distributions with the same mean and median but with different shapes can give us a positive EMD (even when other metrics will not show observable differences): 

```{r}
sim_data %>% 
  arrange(data) %>% 
  transmute(
    data = c(data[group == "A"] + 1.5, data[group == "A"] - 1.5), 
    sample_name = str_c("sample", 101:200),
    group = "B"
  ) %>% 
  bind_rows(
    sim_data[1:50,]
  ) %T>% 
  (function(.x) {
    my_plot <- 
      ggplot(data = .x, aes(x = data, fill = group)) + 
      geom_density(alpha = 0.5) 
      print(my_plot)
  }
  ) %>% 
  summarize(
    emd = 
      calculate_emd_gene(
                vec = setNames(data, sample_name),
                outcomes = setNames(group, sample_name), 
                sample_names = sample_name, 
                binSize = 0.1
      ), 
    mean_difference = 
      (.) %>% 
      filter(group == "A") %>% 
      pull(data) %>% 
      mean() - 
      (.) %>% 
      filter(group == "B") %>% 
      pull(data) %>% 
      mean(), 
    median_difference = 
      (.) %>% 
      filter(group == "A") %>% 
      pull(data) %>% 
      median() - 
      (.) %>% 
      filter(group == "B") %>% 
      pull(data) %>% 
      median()
  ) %>% 
  knitr::kable()

```


Note that the emd value is **not** zero even though the differences in means is 0 (and the median difference is very small), indicating that emd is a better metric for detecting differences in population distributions when distributions are irregular.

## Stimulation relative to basal in Dx and Rx pairs

Our simulated data indicate that the implementation of EMD that we're using passes some basic sanity checks. Now, we apply it to the AML dataset. 


```{r}
stim_names <- 
  aml_data$stimulation %>% 
  unique() %>% 
  as.character()

# input: data frame of stimulation conditions representing a single sample 
# output: two-column tibble: 
#         - stimulation = names of stimulation conditions
#         - emd = EMD corresponding to that stimulation condition relative to basal
aml_emd <- function(data) {
  map_dfr(
    .x = 
      unique(data$stimulation) %>% 
      as.character(), 
    .f = 
      ~ if (.x == "Basal") {
        return(tibble(stimulation = "Basal", emd = 0))
      }
    else { 
      result <- 
        data %>% 
        filter(stimulation %in% c("Basal", .x)) %>% 
        summarize(
          emd = 
            calculate_emd_gene(
              vec = setNames(expression, cell_id), 
              outcomes = setNames(stimulation, cell_id), 
              sample_names = cell_id, 
              binSize = (max(expression) - min(expression)) / 200
            ), 
          stimulation = .x
        )
      return(result)
    }
  )
}



aml_emds <- 
  aml_data %>% 
  mutate(cell_id = 1:nrow(aml_data)) %>% 
  select(
    one_of(
      str_to_lower(SIGNALING_MARKERS), 
      "stimulation", 
      "cell_id", 
      "patient", 
      "condition"
    )
  ) %>% 
  pivot_longer(
    cols = one_of(str_to_lower(SIGNALING_MARKERS)), 
    names_to = "marker", 
    values_to = "expression"
  ) %>% 
  group_by(patient, condition, marker) %>% 
  nest() %>% 
  mutate(
    emds = map(data, aml_emd), 
    mean_difference = 
      map2(
        .x = data, 
        .y = emds,
        ~
        tibble(
          mean_difference = 
            (.) %>% 
            group_by(stimulation) %>% 
            summarize(expression = mean(expression)) %>% 
            pull(expression) - 
            (.) %>% 
            filter(stimulation == "Basal") %>% 
            pull(expression) %>% 
            mean(), 
          stimulation = .y %>% pull(stimulation)
        )
      )
  ) %>% 
  ungroup() %>% 
  transmute(
    patient, 
    condition,
    marker,
    data = 
      map(
        data, 
        ~ (.) %>% 
          group_by(stimulation = as.character(stimulation)) %>% 
          nest() %>% 
          ungroup()
      ), 
    data = 
      pmap(
        list(data, emds, mean_difference), 
        function(x, y, z) {
          x %>% 
            left_join(y, by = "stimulation") %>% 
            left_join(z, by = "stimulation")
        }
      )
  ) %>% 
  unnest(cols = data)
```

Thus, we have calculated all of the EMD scores for each stimulation condition for each patient sample (diagnosis and relapse). 

# Visualizing differences in signaling EMDs

## Dimensionality Reduction:

We can take the EMDs obtained for each sample and stick them together as a vector - and these vectors can then be used for any dimensionality reduction algorithms we choose for visualization. Let's give a try to PCA first...

```{r}
emd_matrix <- 
  aml_emds %>% 
  pivot_wider(
    id_cols = c(patient, condition), 
    names_from = c(marker, stimulation), 
    values_from = emd
  ) %>% 
  select(-contains("Basal")) %>% 
  drop_na()

emd_matrix

emd_pca <- 
  prcomp(
    x = emd_matrix %>% select(-patient, -condition), 
    scale = TRUE, 
    center = TRUE
  ) 

#calculate variance explained by first two principal components
var_explained <- 
  emd_pca$sdev^2 / sum(emd_pca$sdev^2)

emd_pca <- 
  emd_pca %>% 
  (function(.x) {.x$x}) %>% 
  as_tibble() %>% 
  select(PC1, PC2) %>% 
  bind_cols(emd_matrix)

emd_pca %>% 
  ggplot(aes(x = PC1, y = PC2, fill = condition)) + 
  geom_line(aes(group = patient), color = "gray60") + 
  geom_point(shape = 21, size = 2) + 
  scale_fill_discrete(
    breaks = c("Healthy", "Dx", "Rx"), 
    labels = c("Healthy", "Diagnosis", "Relapse")
  ) + 
  labs(
    x = str_glue("PC1 ({var}%)", var = (var_explained[[1]] * 100) %>% round(1)), 
    y = str_glue("PC2 ({var}%)", var = (var_explained[[2]] * 100) %>% round(1)), 
    fill = NULL
  )
```

In general, it looks like the red (`Diagnosis`) dots are closer to the healthy dots than the relapse ones, potentially indicating that relapse samples have signaling pattern that is less similar to healthy signaling than diagnostic samples. 

However, we can also note that the variance explained by each principal component is relatively low, indicating that our dataset is not super well-represented in two linear dimensions. We can also give tSNE a shot to see if it tells a different story...

```{r}
set.seed(5)

emd_tsne <- 
  Rtsne(
    X = emd_matrix %>% select(-patient, -condition), 
    dims = 2, 
    perplexity = 7
  ) %>% 
  (function(.x) {.x$Y}) %>% 
  as_tibble() %>% 
  rename(tSNE1 = V1, tSNE2 = V2) %>% 
  bind_cols(emd_matrix)

emd_tsne %>% 
  ggplot(aes(x = tSNE1, y = tSNE2, fill = condition)) + 
  geom_line(aes(group = patient), color = "gray60") + 
  geom_point(shape = 21, size = 2) + 
  scale_fill_discrete(
    breaks = c("Healthy", "Dx", "Rx"), 
    labels = c("Healthy", "Diagnosis", "Relapse")
  ) + 
  labs(
    fill = NULL
  )
```


In general, the same result seems to hold, although I'll note that this plot is very sensitive to perplexity and seed (because the number of observations is relatively small). 


```{r, eval = FALSE, echo = FALSE}
## Heatmap: 

my_heatmap <- 
  pheatmap(
  mat = 
    emd_matrix %>% 
    select(-patient, -condition) %>% 
    as.matrix() %>% 
    set_rownames(str_c(emd_matrix$patient, emd_matrix$condition, sep = "_")), 
  annotation_row = 
    emd_matrix %>% 
    select(patient, condition) %>% 
    as.data.frame() %>% 
    set_rownames(str_c(emd_matrix$patient, emd_matrix$condition, sep = "_")), 
  annotation_col =
    emd_matrix %>% 
    select(-patient, -condition) %>% 
    colnames() %>% 
    str_split(pattern = "_", simplify = TRUE) %>% 
    as_tibble() %>% 
    rename(marker = V1, stimulation = V2) %>% 
    as.data.frame() %>% 
    set_rownames(emd_matrix %>% select(-patient, -condition) %>% colnames),
  scale = "column"
  
)

my_heatmap
```

## Custom plots and histograms

```{r, out.width = "100%", warning = FALSE, message = FALSE}
all_patients <- 
  aml_emds %>% 
  pull(patient) %>% 
  unique()

my_patient <- all_patients[[8]]

patient_plot <- function(my_patient) { 
  aml_emds %>%
    filter(patient == my_patient) %>% 
    
    ggplot(aes(x = condition, y = emd, fill = stimulation)) + 
    geom_line(aes(group = stimulation)) + 
    geom_point(shape = 21, size = 3) + 
    facet_grid(cols = vars(marker)) + 
    labs(title = my_patient)
}

all_patients %>% 
  map(patient_plot) %>% 
  walk(print)
```

And the overall plot...

```{r}
aml_emds %>%
  filter(condition != "Healthy") %>% 
  group_by(stimulation, condition, marker) %>% 
  summarize(emd = mean(emd)) %>% 
  ggplot(aes(x = condition, y = emd, fill = stimulation)) + 
  geom_hline(
    aes(yintercept = healthy_mean, color = stimulation), 
    data = 
      aml_emds %>% 
      filter(condition == "Healthy") %>% 
      group_by(stimulation) %>% 
      summarize(healthy_mean = mean(emd)), 
    linetype = "dashed"
  ) + 
  geom_line(aes(group = stimulation)) + 
  geom_point(shape = 21, size = 3) + 
  facet_grid(cols = vars(marker)) + 
  labs(
    title = "Mean EMD for phosphosignals across all patients", 
    subtitle = "Note: Dotted lines indicate average in the healthy samples"
  )
```


Future directions: 

* Look more closely at how Dana Pe'er's lab has expressed EMD data visually and if there are any best practices re: handling the data that I may have missed.

* Find a more intuitive way to plot the heatmap (I will use the `heatmaply` package, which I have [read good things about](https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html))

* Perform statistical tests to determine how the paired samples differ in a more quantitative way



  
